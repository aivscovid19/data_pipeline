{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScieloMiner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/7ATWqw6zHLGnW+OM3j13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khodizoda/ai_vs_covid19/blob/master/ScieloMiner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmA_WexKKmgM"
      },
      "source": [
        "# Set up and update\n",
        "Scielo miner by Adrian\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owtdr4dIKl9j"
      },
      "source": [
        "!apt-get update && apt-get upgrade\n",
        "!apt install chromium-chromedriver\n",
        "!pip install centaurMiner==0.0.8\n",
        "\n",
        "!apt autoremove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sO4iC_lKiB8"
      },
      "source": [
        "from dateutil.parser import parse\n",
        "import centaurminer as mining\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "class ScieloMiner():\n",
        "  '''\n",
        "  Miner for https://scielo.org\n",
        "  '''\n",
        "  def __init__():\n",
        "    pass\n",
        "\n",
        "  class ScieloLocations(mining.PageLocations):\n",
        "      \"\"\"Locations on the page to be gathered by Selenium webdriver\n",
        "      \n",
        "      The locations may be declared here as static variables of any type, to be retrieved\n",
        "      as keys on the centaurminer.MiningEngine.results dictionary. Some examples of data that\n",
        "      can be declared here:\n",
        "\n",
        "      centaurminer.Metadata: Selenium retrieved elements from a page metadata\n",
        "      centaurminer.Element: Selenium retrived elements from a page body.\n",
        "      string: Strings declared here won't change, independently of the page searched.\n",
        "      \"\"\"\n",
        "\n",
        "      source = mining.MetaData(\"citation_journal_title\")\n",
        "      date_publication = mining.Element(\"css_selector\", \"h3\")\n",
        "      body = mining.Element(\"css_selector\", \"#article-body, .index\\,pt > p, .index\\,en > p, .index\\,es > p\")\n",
        "      abstract = mining.Element(\"css_selector\", \".trans-abstract > p:not([class^=sec]), .trans-abstract > div.section\")\n",
        "      keywords = mining.Element(\"css_selector\", \".trans-abstract > p:last-of-type\")\n",
        "      references = mining.Element(\"css_selector\", \"p.ref\")\n",
        "      organization_affiliated = mining.Element(\"css_selector\", \"p.aff\").get_attribute('innerHTML')\n",
        "      license = \"https://scielo.org/en/about-scielo/open-access-statement/\"\n",
        "      id = mining.Complex()\n",
        "      pass\n",
        "\n",
        "  class ScieloEngine(mining.MiningEngine):\n",
        "      \"\"\"Mining Engine to get data from elements declared on centaurminer.PageLocations\n",
        "\n",
        "      Here it's possible to process elements retrieved from centaurminer.PageLocations\n",
        "      before gathering the results as a dictionary. To modify a specific element, declare\n",
        "      a new method in the form get_<key>.\n",
        "\n",
        "      Example:\n",
        "          def get_authors(self, element):\n",
        "              return TagList(self.get(element, several=True))\n",
        "      \"\"\"\n",
        "\n",
        "      #########################\n",
        "      ### Utilities Methods ###\n",
        "      #########################\n",
        "      \n",
        "      @staticmethod\n",
        "      def TagList(str_list, tag=\"item\"):\n",
        "          \"\"\" Returns a string from a joined list with elements separated by HTML-like tags\n",
        "          Note:\n",
        "              This method is overwritting base class centaurminer.MiningEngine\n",
        "              default `CollectURLs` method.\n",
        "          Args:\n",
        "              str_list (list):     List of strings to be joined with HTML-like tags.\n",
        "              tag (str, optional): Tag used to separate the elements in the form <></>  \n",
        "          Returns:\n",
        "              A string containing the list elements separated by HTML-like tags,\n",
        "              None if str_list is None or empty.\n",
        "          \"\"\"\n",
        "          if str_list:\n",
        "              return ''.join(map(lambda s: f'<{tag}>{s.strip()}</{tag}>', str_list))\n",
        "          return None\n",
        "\n",
        "      @staticmethod\n",
        "      def __format_author(author):\n",
        "          \"\"\"Formats a single author entry in full name format.\"\"\"\n",
        "          author = ' '.join(author.split(\",\")[::-1])\n",
        "          return author.title().strip()\n",
        "\n",
        "      @staticmethod\n",
        "      def __parse_keywords(keys):\n",
        "          \"\"\"Extract keywords from HTML element\"\"\"\n",
        "          key_strings = [ \n",
        "                      \"keywords\",\n",
        "                      \"key words\",\n",
        "                      \"palavras-chave\",\n",
        "                      \"palavras chave\",\n",
        "                      \"index terms\",\n",
        "                      \"descritores\"\n",
        "                    ]\n",
        "          if not keys:\n",
        "              return None\n",
        "          for i in key_strings:\n",
        "              if keys.lower().startswith(i):\n",
        "                  keys = keys[len(i):]\n",
        "          return keys.replace(':', ' ').replace(';',',').split(',')\n",
        "\n",
        "      ##################################\n",
        "      ### Element Processing Methods ###\n",
        "      ##################################\n",
        "\n",
        "      def get_id(self, element):\n",
        "          \"\"\"Return unique identifier for article ID.\"\"\"\n",
        "          return str(uuid.uuid4())\n",
        "\n",
        "\n",
        "      def get_abstract(self, element):\n",
        "          \"\"\"Fetch abstract information from article URL.\"\"\"\n",
        "          return '\\n'.join(self.get(element, several=True))\n",
        "\n",
        "\n",
        "      def get_body(self, element):\n",
        "          \"\"\"Gather body text from article URL\n",
        "          Note: \n",
        "              If body is retrieved from #article-body selector, it's safe\n",
        "              to assume that it'll be pretty formatted. Otherwise, it's\n",
        "              required to process <p> tags to retrieve body information.\n",
        "          Args:\n",
        "              element(:obj: `centaurminer.Element`): Page element to gather body data from.\n",
        "          Return:\n",
        "              String comprising whole body data\n",
        "          \"\"\"\n",
        "          body = self.get(element, several=True)\n",
        "          # Return if get from #article-body selector\n",
        "          if len(body) == 1:\n",
        "              return body[0]\n",
        "          cleaned_paragraphs = []\n",
        "          try:\n",
        "              for idx, p in enumerate(body):\n",
        "                  if p.lower() in [\"resumo\", \"abstract\", \"resumen\"]:\n",
        "                      abstract_index = idx\n",
        "          # Clean up and join the paragraphs    \n",
        "              for p in body[:abstract_index]:\n",
        "                  p = p.replace('&nbsp;',' ').strip()\n",
        "                  just_whitespace = all(char == \" \" for char in p)\n",
        "                  if not just_whitespace:\n",
        "                      cleaned_paragraphs.append(p)\n",
        "          except:\n",
        "              pass\n",
        "          if not len(cleaned_paragraphs):\n",
        "              return None \n",
        "          return \"\\n\".join(cleaned_paragraphs)\n",
        "\n",
        "\n",
        "      def get_date_publication(self, element):\n",
        "          \"\"\"\"Gather article date publication, in YYYY-MM-DD format\n",
        "          Args:\n",
        "              element(:obj: `centaurminer.Element`): Page element to\n",
        "                  gather body data from.\n",
        "          Return:\n",
        "              String representing date publication, in format YYYY-MM-DD.\n",
        "          \"\"\"\n",
        "          try:\n",
        "              return str((self.get(element).split('Epub')[1]).date())\n",
        "          except (AttributeError, IndexError):\n",
        "              return None\n",
        "\n",
        "      def get_organization_affiliated(self, element):\n",
        "          \"\"\"Returns a string with article authors organizations, separated by HTML-like elements\"\"\"\n",
        "          orgs = [o.split('</sup>')[-1] for o in self.get(element, several=True)]\n",
        "          return self.TagList(orgs, \"orgs\")\n",
        "\n",
        "      def get_references(self, element):\n",
        "          \"\"\"Returns a string with article references, separated by HTML-like elements\"\"\"\n",
        "          reflist = self.get(element, several=True)\n",
        "          refs = [r.replace('[ Links ]', '').strip('0123456789. ') for r in reflist]\n",
        "          return self.TagList(refs)\n",
        "\n",
        "      def get_authors(self, element):\n",
        "          \"\"\"Returns a string with article authors from search engine, separated by HTML-like elements\"\"\"\n",
        "          authors = map(self.__format_author, self.get(element, several=True))\n",
        "          return self.TagList(list(dict.fromkeys(authors)), 'author')\n",
        "\n",
        "      def get_keywords(self, element):\n",
        "          \"\"\"Gather article keywords from centaurminer.Element object.\n",
        "          Args:\n",
        "              element(:obj: `centaurminer.Element`): Page element to gather keywords from.\n",
        "          Returns:\n",
        "              String comprising keywords separated by HTML-like tags.\n",
        "          \"\"\"\n",
        "          keys = self.__parse_keywords(self.get(element))\n",
        "          return self.TagList(keys, \"keyword\")\n",
        "\n",
        "      def gather(self, url):\n",
        "          \"\"\"Retrieve mined information from a specific URL\"\"\"\n",
        "          super().gather(url)\n",
        "          self.results['acquisition_date'] = self.results.pop('date_aquisition')\n",
        "          self.results['date']             = self.results.pop('date_publication')\n",
        "          self.results['pdf_link']         = self.results.pop('extra_link')\n",
        "          self.results['link']             = self.results.pop('url')\n",
        "          # if not self.results['abstract']:\n",
        "          #     self.results['abstract'] = self.results['body']\n",
        "          #     if not miner.results['abstract'] or not self.results['title']:\n",
        "          #         self.results = None\n",
        "          # pass"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}